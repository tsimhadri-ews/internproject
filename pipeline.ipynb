{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "7f60c22f-88c8-4457-8232-91ee012d94bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting scikit-learn\n",
      "  Using cached scikit_learn-1.5.0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (13.4 MB)\n",
      "Collecting joblib>=1.2.0\n",
      "  Using cached joblib-1.4.2-py3-none-any.whl (301 kB)\n",
      "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.9/site-packages (from scikit-learn) (1.8.0)\n",
      "Collecting threadpoolctl>=3.1.0\n",
      "  Using cached threadpoolctl-3.5.0-py3-none-any.whl (18 kB)\n",
      "Requirement already satisfied: numpy>=1.19.5 in /usr/local/lib/python3.9/site-packages (from scikit-learn) (1.21.6)\n",
      "Installing collected packages: threadpoolctl, joblib, scikit-learn\n",
      "Successfully installed joblib-1.4.2 scikit-learn-1.5.0 threadpoolctl-3.5.0\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip available: \u001b[0m\u001b[31;49m22.2.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.0\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Requirement already satisfied: kfp in /usr/local/lib/python3.9/site-packages (1.8.13)\n",
      "Requirement already satisfied: requests-toolbelt<1,>=0.8.0 in /usr/local/lib/python3.9/site-packages (from kfp) (0.10.0)\n",
      "Requirement already satisfied: google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0dev,>=1.31.5 in /usr/local/lib/python3.9/site-packages (from kfp) (2.10.2)\n",
      "Requirement already satisfied: typer<1.0,>=0.3.2 in /usr/local/lib/python3.9/site-packages (from kfp) (0.6.1)\n",
      "Requirement already satisfied: protobuf<4,>=3.13.0 in /usr/local/lib/python3.9/site-packages (from kfp) (3.19.5)\n",
      "Requirement already satisfied: strip-hints<1,>=0.1.8 in /usr/local/lib/python3.9/site-packages (from kfp) (0.1.10)\n",
      "Requirement already satisfied: fire<1,>=0.3.1 in /usr/local/lib/python3.9/site-packages (from kfp) (0.4.0)\n",
      "Requirement already satisfied: click<9,>=7.1.2 in /usr/local/lib/python3.9/site-packages (from kfp) (8.1.3)\n",
      "Requirement already satisfied: pydantic<2,>=1.8.2 in /usr/local/lib/python3.9/site-packages (from kfp) (1.10.2)\n",
      "Requirement already satisfied: uritemplate<4,>=3.0.1 in /usr/local/lib/python3.9/site-packages (from kfp) (3.0.1)\n",
      "Requirement already satisfied: google-auth<2,>=1.6.1 in /usr/local/lib/python3.9/site-packages (from kfp) (1.35.0)\n",
      "Requirement already satisfied: kfp-pipeline-spec<0.2.0,>=0.1.14 in /usr/local/lib/python3.9/site-packages (from kfp) (0.1.16)\n",
      "Requirement already satisfied: kfp-server-api<2.0.0,>=1.1.2 in /usr/local/lib/python3.9/site-packages (from kfp) (1.8.3)\n",
      "Requirement already satisfied: google-api-python-client<2,>=1.7.8 in /usr/local/lib/python3.9/site-packages (from kfp) (1.12.11)\n",
      "Requirement already satisfied: docstring-parser<1,>=0.7.3 in /usr/local/lib/python3.9/site-packages (from kfp) (0.15)\n",
      "Requirement already satisfied: google-cloud-storage<2,>=1.20.0 in /usr/local/lib/python3.9/site-packages (from kfp) (1.44.0)\n",
      "Requirement already satisfied: kubernetes<19,>=8.0.0 in /usr/local/lib/python3.9/site-packages (from kfp) (18.20.0)\n",
      "Requirement already satisfied: Deprecated<2,>=1.2.7 in /usr/local/lib/python3.9/site-packages (from kfp) (1.2.13)\n",
      "Requirement already satisfied: jsonschema<4,>=3.0.1 in /usr/local/lib/python3.9/site-packages (from kfp) (3.2.0)\n",
      "Requirement already satisfied: absl-py<2,>=0.9 in /usr/local/lib/python3.9/site-packages (from kfp) (1.2.0)\n",
      "Requirement already satisfied: cloudpickle<3,>=2.0.0 in /usr/local/lib/python3.9/site-packages (from kfp) (2.2.0)\n",
      "Requirement already satisfied: tabulate<1,>=0.8.6 in /usr/local/lib/python3.9/site-packages (from kfp) (0.9.0)\n",
      "Requirement already satisfied: PyYAML<6,>=5.3 in /usr/local/lib/python3.9/site-packages (from kfp) (5.4.1)\n",
      "Requirement already satisfied: wrapt<2,>=1.10 in /usr/local/lib/python3.9/site-packages (from Deprecated<2,>=1.2.7->kfp) (1.14.1)\n",
      "Requirement already satisfied: termcolor in /usr/local/lib/python3.9/site-packages (from fire<1,>=0.3.1->kfp) (2.0.1)\n",
      "Requirement already satisfied: six in /usr/local/lib/python3.9/site-packages (from fire<1,>=0.3.1->kfp) (1.16.0)\n",
      "Requirement already satisfied: requests<3.0.0dev,>=2.18.0 in /usr/local/lib/python3.9/site-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0dev,>=1.31.5->kfp) (2.27.1)\n",
      "Requirement already satisfied: googleapis-common-protos<2.0dev,>=1.56.2 in /usr/local/lib/python3.9/site-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0dev,>=1.31.5->kfp) (1.56.4)\n",
      "Requirement already satisfied: httplib2<1dev,>=0.15.0 in /usr/local/lib/python3.9/site-packages (from google-api-python-client<2,>=1.7.8->kfp) (0.20.4)\n",
      "Requirement already satisfied: google-auth-httplib2>=0.0.3 in /usr/local/lib/python3.9/site-packages (from google-api-python-client<2,>=1.7.8->kfp) (0.1.0)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.9/site-packages (from google-auth<2,>=1.6.1->kfp) (4.7.2)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.9/site-packages (from google-auth<2,>=1.6.1->kfp) (0.2.8)\n",
      "Requirement already satisfied: setuptools>=40.3.0 in /usr/local/lib/python3.9/site-packages (from google-auth<2,>=1.6.1->kfp) (65.4.0)\n",
      "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.9/site-packages (from google-auth<2,>=1.6.1->kfp) (4.2.4)\n",
      "Requirement already satisfied: google-cloud-core<3.0dev,>=1.6.0 in /usr/local/lib/python3.9/site-packages (from google-cloud-storage<2,>=1.20.0->kfp) (2.3.2)\n",
      "Requirement already satisfied: google-resumable-media<3.0dev,>=1.3.0 in /usr/local/lib/python3.9/site-packages (from google-cloud-storage<2,>=1.20.0->kfp) (2.4.0)\n",
      "Requirement already satisfied: pyrsistent>=0.14.0 in /usr/local/lib/python3.9/site-packages (from jsonschema<4,>=3.0.1->kfp) (0.18.1)\n",
      "Requirement already satisfied: attrs>=17.4.0 in /usr/local/lib/python3.9/site-packages (from jsonschema<4,>=3.0.1->kfp) (22.1.0)\n",
      "Requirement already satisfied: certifi in /usr/local/lib/python3.9/site-packages (from kfp-server-api<2.0.0,>=1.1.2->kfp) (2022.9.24)\n",
      "Requirement already satisfied: urllib3>=1.15 in /usr/local/lib/python3.9/site-packages (from kfp-server-api<2.0.0,>=1.1.2->kfp) (1.26.12)\n",
      "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.9/site-packages (from kfp-server-api<2.0.0,>=1.1.2->kfp) (2.8.2)\n",
      "Requirement already satisfied: websocket-client!=0.40.0,!=0.41.*,!=0.42.*,>=0.32.0 in /usr/local/lib/python3.9/site-packages (from kubernetes<19,>=8.0.0->kfp) (1.4.1)\n",
      "Requirement already satisfied: requests-oauthlib in /usr/local/lib/python3.9/site-packages (from kubernetes<19,>=8.0.0->kfp) (1.3.1)\n",
      "Requirement already satisfied: typing-extensions>=4.1.0 in /usr/local/lib/python3.9/site-packages (from pydantic<2,>=1.8.2->kfp) (4.3.0)\n",
      "Requirement already satisfied: wheel in /usr/local/lib/python3.9/site-packages (from strip-hints<1,>=0.1.8->kfp) (0.37.1)\n",
      "Requirement already satisfied: google-crc32c<2.0dev,>=1.0 in /usr/local/lib/python3.9/site-packages (from google-resumable-media<3.0dev,>=1.3.0->google-cloud-storage<2,>=1.20.0->kfp) (1.5.0)\n",
      "Requirement already satisfied: pyparsing!=3.0.0,!=3.0.1,!=3.0.2,!=3.0.3,<4,>=2.4.2 in /usr/local/lib/python3.9/site-packages (from httplib2<1dev,>=0.15.0->google-api-python-client<2,>=1.7.8->kfp) (3.0.9)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.9/site-packages (from pyasn1-modules>=0.2.1->google-auth<2,>=1.6.1->kfp) (0.4.8)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.9/site-packages (from requests<3.0.0dev,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0dev,>=1.31.5->kfp) (3.4)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.9/site-packages (from requests<3.0.0dev,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0dev,>=1.31.5->kfp) (2.0.12)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.9/site-packages (from requests-oauthlib->kubernetes<19,>=8.0.0->kfp) (3.2.1)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip available: \u001b[0m\u001b[31;49m22.2.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.0\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install scikit-learn\n",
    "!pip install kfp\n",
    "from typing import NamedTuple\n",
    "import pandas as pd \n",
    "import pickle\n",
    "import tensorflow as tf\n",
    "import numpy as np \n",
    "\n",
    "from kfp import dsl\n",
    "\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "\n",
    "import time\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "51604aee-6b2e-4db0-9534-dfa3fc9738eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#test \n",
    "def read_data() -> list:\n",
    "    data = [1, 2, 3, 4, 5]\n",
    "    return data\n",
    "\n",
    "\n",
    "from typing import NamedTuple\n",
    "\n",
    "import kfp \n",
    "import kfp\n",
    "from kfp import dsl\n",
    "from kfp import components\n",
    "\n",
    "\n",
    "def read_file() -> None:\n",
    "    \n",
    "    def zscore_normalization(df, name):\n",
    "        mean = df[name].mean()\n",
    "        sd = df[name].std()\n",
    "        df[name] = (df[name] - mean) / sd\n",
    "\n",
    "    def encode_text(df, name):\n",
    "        from sklearn.preprocessing import OrdinalEncoder\n",
    "        enc = OrdinalEncoder()\n",
    "        data = enc.fit_transform(df[name].values.reshape(-1,1))\n",
    "        df[name] = data.flatten()\n",
    "\n",
    "    def column_names():\n",
    "        f = open(\"kddcup.names.txt\")\n",
    "        s = f.read()\n",
    "        arr = s.split(\"\\n\")[1:-1]\n",
    "        cols = [a[0:a.index(\":\")] for a in arr]\n",
    "        cols.append(\"outcome\")\n",
    "        return cols\n",
    "\n",
    "    def preprocess(df):\n",
    "        #df.columns = column_names()\n",
    "        df.columns = [\n",
    "        'duration',\n",
    "        'protocol_type',\n",
    "        'service',\n",
    "        'flag',\n",
    "        'src_bytes',\n",
    "        'dst_bytes',\n",
    "        'land',\n",
    "        'wrong_fragment',\n",
    "        'urgent',\n",
    "        'hot',\n",
    "        'num_failed_logins',\n",
    "        'logged_in',\n",
    "        'num_compromised',\n",
    "        'root_shell',\n",
    "        'su_attempted',\n",
    "        'num_root',\n",
    "        'num_file_creations',\n",
    "        'num_shells',\n",
    "        'num_access_files',\n",
    "        'num_outbound_cmds',\n",
    "        'is_host_login',\n",
    "        'is_guest_login',\n",
    "        'count',\n",
    "        'srv_count',\n",
    "        'serror_rate',\n",
    "        'srv_serror_rate',\n",
    "        'rerror_rate',\n",
    "        'srv_rerror_rate',\n",
    "        'same_srv_rate',\n",
    "        'diff_srv_rate',\n",
    "        'srv_diff_host_rate',\n",
    "        'dst_host_count',\n",
    "        'dst_host_srv_count',\n",
    "        'dst_host_same_srv_rate',\n",
    "        'dst_host_diff_srv_rate',\n",
    "        'dst_host_same_src_port_rate',\n",
    "        'dst_host_srv_diff_host_rate',\n",
    "        'dst_host_serror_rate',\n",
    "        'dst_host_srv_serror_rate',\n",
    "        'dst_host_rerror_rate',\n",
    "        'dst_host_srv_rerror_rate',\n",
    "        'outcome'\n",
    "        ]\n",
    "        for col in df.columns:\n",
    "            t = (df[col].dtype)\n",
    "            if t == int or t == float:\n",
    "                zscore_normalization(df, col)\n",
    "            else:\n",
    "                encode_text(df, col)\n",
    "        df.dropna(inplace=True,axis=1)\n",
    "        for col in df.columns:\n",
    "            if len(df[col].unique()) == 1:\n",
    "                df.drop(col, inplace=True,axis=1)\n",
    "\n",
    "        df.loc[df['outcome'] != \"normal.\", 'outcome']  = 1\n",
    "        df.loc[df['outcome'] == \"normal.\", 'outcome']  = 0\n",
    "\n",
    "        correlation = df.corrwith(df['outcome'])\n",
    "        for num in correlation:\n",
    "            if num >= -0.05 and num <= 0.05:\n",
    "                df.drop(df.columns[row], axis=1, inplace=True)\n",
    "        return df\n",
    "    \n",
    "    \n",
    "    from sklearn.model_selection import train_test_split\n",
    "    import os \n",
    "    import pandas as pd\n",
    "    import numpy as np \n",
    "    \n",
    "    file_path = 'https://raw.githubusercontent.com/tsimhadri-ews/internproject/intrusion-detection-0/src/kddcup.data_10_percent_corrected.csv'\n",
    "    df = pd.read_csv(file_path)\n",
    "    df = preprocess(df)\n",
    "    \n",
    "\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = train_test_split(df.drop(columns=[\"outcome\"]), df[\"outcome\"], test_size=0.2)\n",
    "    \n",
    "    folder_path = './data'\n",
    "\n",
    "    if not os.path.exists(folder_path):\n",
    "        os.makedirs(folder_path)\n",
    "        print(f\"Folder '{folder_path}' created successfully.\")\n",
    "    else:\n",
    "        print(f\"Folder '{folder_path}' already exists.\")\n",
    "    \n",
    "    \n",
    "    \n",
    "    np.save(f'data/X_train.npy', X_train)\n",
    "    os.rename(f'data/X_train.npy', X_train_artifact.path)\n",
    "    np.save(f'data/X_test.npy', X_test)\n",
    "    os.rename(\"/tmp/X_test.npy\", X_test_artifact.path)\n",
    "    np.save(f'data/y_train.npy', y_train)\n",
    "    os.rename(f'data/y_train.npy', y_train_artifact.path)\n",
    "    np.save(f'data/y_test.npy', y_test)\n",
    "    os.rename(f'data/y_test.npy', y_test_artifact.path)\n",
    "    \n",
    "    metrics.log_metric(\"Len x_train\", X_train.shape[0])\n",
    "    metrics.log_metric(\"Len x_test\", X_test.shape[0])\n",
    "    \n",
    "    \n",
    "    print(X_train, X_test, y_train, y_test)\n",
    "    return X_train, X_test, y_train, y_test\n",
    "    \n",
    "\n",
    "#read_file()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "c0462333-fc3f-4a22-b5eb-d501882b2780",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "def train_op() -> None:\n",
    "    import pickle\n",
    "    import pandas as pd\n",
    "    from sklearn.ensemble import RandomForestClassifier\n",
    "    from sklearn.metrics import accuracy_score, f1_score\n",
    "    import numpy as np \n",
    "    import json\n",
    "    import os \n",
    "    \n",
    "    # Convert JSON strings back to DataFrames\n",
    "    \"\"\"\n",
    "    X_train = pd.read_json(X_train_json)\n",
    "    X_test = pd.read_json(X_test_json)\n",
    "    y_train = pd.read_json(y_train_json, typ='series')\n",
    "    y_test = pd.read_json(y_test_json, typ='series')\n",
    "    \n",
    "    X_train = np.load(f'data/X_train.npy',allow_pickle=True)\n",
    "    X_test = np.load(f'data/X_test.npy',allow_pickle=True)\n",
    "    y_train = np.load(f'data/y_train.npy',allow_pickle=True)\n",
    "    y_test = np.load(f'data/y_train.npy',allow_pickle=True)\n",
    "    \"\"\"\n",
    "    X_train = np.load(X_train.path) \n",
    "    X_test = np.load(X_test.path)\n",
    "    y_train = np.load(y_train.path) \n",
    "    y_test = np.load(y_test.path)\n",
    "    \n",
    "    model = RandomForestClassifier()\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    f1 = f1_score(y_test, y_pred)\n",
    "    print(f\"Accuracy: {accuracy}\")\n",
    "    print(f\"F1 Score: {f1}\")\n",
    "    \n",
    "    #Kubeflox metrics export\n",
    "    \n",
    "    metrics.log_metric(\"Test accuracy\", accuracy)\n",
    "    metrics.log_metric(\"F1 Score\", f1)\n",
    "    \n",
    "    #implement TFServing \n",
    "\n",
    "    with open(f'model.pkl', 'wb') as f:\n",
    "        pickle.dump(model, f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "01f5feb9-54b0-4b11-8e9b-41fc2e183308",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "def predict_op(input_data:str) -> str:\n",
    "    with open('model.pkl', 'rb') as f:\n",
    "        model = pickle.load(f)\n",
    "    return str(model.predict(test_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "44896ccd-c58a-4e0d-bdb4-89d455730d3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from kfp import components\n",
    "\n",
    "\n",
    "#preprocess_op = components.func_to_container_op(func=preprocess_op, output_component_file='preprocess.yaml', base_image='python:3.7', packages_to_install=['pandas', 'scikit-learn'])\n",
    "\n",
    "read_csv_op = components.func_to_container_op(func=read_file, output_component_file='read.yaml', base_image='python:3.7', packages_to_install=['pandas','scikit-learn', 'kfp', 'numpy'])\n",
    "#preprocess_op = components.func_to_container_op(func=preprocess_op, output_component_file='preprocess.yaml', base_image='python:3.7', packages_to_install=['pandas', 'scikit-learn'])\n",
    "#preprocess_op = components.func_to_container_op(func=preprocess_op, output_component_file='preprocess.yaml', base_image='python:3.7', packages_to_install=['pandas', 'scikit-learn'])\n",
    "train_op = components.func_to_container_op(func=train_op, output_component_file='train.yaml', base_image='python:3.7', packages_to_install=['pandas', 'scikit-learn','numpy' ])\n",
    "#predict_op = components.func_to_container_op(func=predict_op,output_component_file='predict.yaml', base_image='python:3.7', packages_to_install=['pandas', 'scikit-learn', 'numpy'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "f7c430af-2221-4ecd-9395-2ca5f8114c31",
   "metadata": {},
   "outputs": [],
   "source": [
    "import kfp\n",
    "from kfp import dsl\n",
    "\n",
    "#read_data_op = kfp.components.load_component_from_file('read.yaml')\n",
    "preprocess_data_op = kfp.components.load_component_from_file('preprocess.yaml')\n",
    "train_op = kfp.components.load_component_from_file('train.yaml')\n",
    "#predict_op = kfp.components.load_component_from_file('predict.yaml')\n",
    "\n",
    "\n",
    "@dsl.pipeline(\n",
    "    name='Machine Learning Pipeline',\n",
    "    description='A pipeline to preprocess, train, and predict using sklearn and tensorflow'\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def ml_pipeline():  #(file_path:str)\n",
    "    #read_csv = read_csv_op()\n",
    "    preprocess = read_csv_op()\n",
    "    train = train_op()\n",
    "    #predict_task = predict_op(preprocess.outputs['X_test'])\n",
    "\n",
    "    \n",
    "    \n",
    "# Compile the pipeline\n",
    "kfp.compiler.Compiler().compile(ml_pipeline, 'pipeline22.yaml')\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "e8609710-ee07-4c9e-abe7-c4e72b846495",
   "metadata": {},
   "outputs": [],
   "source": [
    "from kfp import compiler\n",
    "\n",
    "pipeline_func = ml_pipeline\n",
    "pipeline_filename = pipeline_func.__name__ + '.yaml'\n",
    "\n",
    "compiler.Compiler().compile(pipeline_func, pipeline_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1aeabcc4-5da0-47be-99c2-297c0550997a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  },
  "toc-autonumbering": true,
  "toc-showmarkdowntxt": true
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
